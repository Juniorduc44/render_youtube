# autotime_bot.py
from flask import Flask, request, jsonify, Response
import openai, yt_dlp, re, os, time, sqlite3, threading
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from datetime import datetime, timedelta
import urllib.request

app = Flask(__name__)

# === CONFIG ===
openai.api_key = os.getenv('OPENAI_API_KEY')
REFRESH_TOKEN = os.getenv('REFRESH_TOKEN')
CLIENT_ID = os.getenv('CLIENT_ID')
CLIENT_SECRET = os.getenv('CLIENT_SECRET')
KEYWORDS = os.getenv('KEYWORDS', '#tutorial,how to,learn python')
CHECK_INTERVAL = int(os.getenv('CHECK_INTERVAL', '900'))

# === DB ===
conn = sqlite3.connect('autotime.db', check_same_thread=False)
conn.execute('''CREATE TABLE IF NOT EXISTS processed (video_id TEXT PRIMARY KEY, posted_at TEXT)''')
conn.commit()

log_buffer = []

# === YouTube ===
def get_youtube():
    creds = Credentials(None, refresh_token=REFRESH_TOKEN,
                        token_uri="https://oauth2.googleapis.com/token",
                        client_id=CLIENT_ID, client_secret=CLIENT_SECRET,
                        scopes=['https://www.googleapis.com/auth/youtube.force-ssl'])
    return build('youtube', 'v3', credentials=creds)

# === Transcript ===
def get_transcript(video_id):
    try:
        ydl_opts = {'skip_download': True, 'writesubtitles': True, 'subtitleslangs': ['en'], 'quiet': True}
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(f"https://youtube.com/watch?v={video_id}", download=False)
            subs = info.get('automatic_captions', {}).get('en', [{}])
            if not subs: return None
            url = subs[0]['url']
            with urllib.request.urlopen(url, timeout=10) as f:
                data = f.read().decode()
            lines = re.findall(r'<text start="(\d+\.?\d*)" dur=".*?">(.*?)</text>', data)
            transcript = ""
            for start, text in lines:
                sec = int(float(start))
                ts = f"[{sec//3600:02d}:{(sec%3600)//60:02d}:{sec%60:02d}] {text.strip()}\n"
                transcript += ts
            return transcript
    except Exception as e:
        log(f"Transcript error: {e}")
        return None

# === Summary ===
def generate_summary(transcript, title, video_id):
    prompt = f"""
### YouTube Transcript Summary: {title}

**Core Message:** [1 powerful sentence]

---

#### **Key Points with Timestamps**

1. **[00:00:00](https://youtube.com/watch?v={video_id}?t=0s)**  
   - Point

---

#### **Action Steps / Takeaways**
- Do this

---

**Final Takeaway:**  
> “Quote.”

*Generated by AutoTime.ai – Free timestamps. Creator: Reply 'remove' to delete.*

Cleaned Transcript:
{transcript[:14000]}
"""
    try:
        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=800
        )
        return response.choices[0].message.content
    except Exception as e:
        log(f"Summary error: {e}")
        return None

# === Post ===
def post_comment(video_id, summary):
    try:
        youtube = get_youtube()
        res = youtube.commentThreads().insert(part="snippet", body={
            "snippet": {
                "videoId": video_id,
                "topLevelComment": {"snippet": {"textOriginal": summary}}
            }
        }).execute()
        conn.execute("INSERT INTO processed VALUES (?, ?)", (video_id, datetime.now().isoformat()))
        conn.commit()
        link = f"https://youtube.com/watch?v={video_id}&lc={res['id']}"
        log(f"POSTED: {link}")
        return link
    except Exception as e:
        log(f"Post failed: {e}")
        return None

# === Search ===
def search_new_videos():
    youtube = get_youtube()
    query = KEYWORDS.replace(',', ' OR ')
    published_after = (datetime.utcnow() - timedelta(hours=1)).isoformat("T") + "Z"
    
    try:
        request = youtube.search().list(
            part="snippet",
            q=query,
            type="video",
            order="date",
            publishedAfter=published_after,
            maxResults=10
        )
        response = request.execute()
        new_videos = []
        for item in response.get('items', []):
            vid = item['id']['videoId']
            title = item['snippet']['title']
            if not conn.execute("SELECT 1 FROM processed WHERE video_id=?", (vid,)).fetchone():
                new_videos.append((vid, title))
        return new_videos
    except Exception as e:
        log(f"Search error: {e}")
        return []

# === Log Helper ===
def log(msg):
    print(msg)
    log_buffer.append(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}")
    if len(log_buffer) > 100:
        log_buffer.pop(0)

# === Bot Loop ===
def run_bot():
    while True:
        log("Scanning for new videos...")
        videos = search_new_videos()
        for vid, title in videos:
            log(f"Found: {title}")
            transcript = get_transcript(vid)
            if transcript:
                summary = generate_summary(transcript, title, vid)
                if summary:
                    post_comment(vid, summary)
                time.sleep(30)
        time.sleep(CHECK_INTERVAL)

# === API Endpoints ===
@app.route('/status')
def status():
    count = conn.execute("SELECT COUNT(*) FROM processed").fetchone()[0]
    return jsonify({"processed": count, "running": True})

@app.route('/history')
def history():
    rows = conn.execute("SELECT video_id, posted_at FROM processed ORDER BY posted_at DESC LIMIT 50").fetchall()
    return jsonify([{"video_id": r[0], "posted_at": r[1]} for r in rows])

@app.route('/logs')
def logs():
    def stream():
        for line in log_buffer:
            yield f"data: {line}\n\n"
        while True:
            time.sleep(1)
            yield f"data: [Heartbeat] {datetime.now().strftime('%H:%M:%S')}\n\n"
    return Response(stream(), mimetype='text/event-stream')

# === Start ===
if __name__ == '__main__':
    threading.Thread(target=run_bot, daemon=True).start()
    app.run(host='0.0.0.0', port=8080)