# autotime_full_auto.py
from flask import Flask, request, jsonify
import openai, yt_dlp, re, os, time, sqlite3, threading
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from datetime import datetime, timedelta
import urllib.request

app = Flask(__name__)

# === CONFIG (Environment Variables) ===
openai.api_key = os.getenv('OPENAI_API_KEY')
REFRESH_TOKEN = os.getenv('REFRESH_TOKEN')
CLIENT_ID = os.getenv('CLIENT_ID')
CLIENT_SECRET = os.getenv('CLIENT_SECRET')
KEYWORDS = os.getenv('KEYWORDS', '#tutorial,#howto,learn')  # Comma-separated
CHANNELS = os.getenv('CHANNELS', '')  # Optional: UCXuqSBlHAE6Xw-yeJA0Tunw
CHECK_INTERVAL = int(os.getenv('CHECK_INTERVAL', '900'))  # 15 mins

# === DB: Track processed videos ===
conn = sqlite3.connect('autotime.db', check_same_thread=False)
conn.execute('''CREATE TABLE IF NOT EXISTS processed (video_id TEXT PRIMARY KEY, posted_at TEXT)''')
conn.commit()

# === YouTube Service ===
def get_youtube():
    creds = Credentials(None, refresh_token=REFRESH_TOKEN,
                        token_uri="https://oauth2.googleapis.com/token",
                        client_id=CLIENT_ID, client_secret=CLIENT_SECRET,
                        scopes=['https://www.googleapis.com/auth/youtube.force-ssl'])
    return build('youtube', 'v3', credentials=creds)

# === Transcript Fetch ===
def get_transcript(video_id):
    try:
        ydl_opts = {'skip_download': True, 'writesubtitles': True, 'subtitleslangs': ['en'], 'quiet': True}
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(f"https://youtube.com/watch?v={video_id}", download=False)
            subs = info.get('automatic_captions', {}).get('en', [{}])
            if not subs: return None
            url = subs[0]['url']
            with urllib.request.urlopen(url, timeout=10) as f:
                data = f.read().decode()
            lines = re.findall(r'<text start="(\d+\.?\d*)" dur=".*?">(.*?)</text>', data)
            transcript = ""
            for start, text in lines:
                sec = int(float(start))
                ts = f"[{sec//3600:02d}:{(sec%3600)//60:02d}:{sec%60:02d}] {text.strip()}\n"
                transcript += ts
            return transcript
    except: return None

# === Summarize in Your Format ===
def generate_summary(transcript, title, video_id):
    prompt = f"""
### YouTube Transcript Summary: {title}

**Core Message:** [1 powerful sentence]

---

#### **Key Points with Timestamps**

1. **[00:00:00](https://youtube.com/watch?v={video_id}?t=0s)**  
   - Point

---

#### **Action Steps / Takeaways**
- Do this

---

**Final Takeaway:**  
> “Quote.”

*Generated by AutoTime.ai – Free timestamps. Creator: Reply 'remove' to delete.*

Cleaned Transcript (first 15k chars):
{transcript[:15000]}
"""
    try:
        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=800
        )
        return response.choices[0].message.content
    except: return None

# === Post Comment ===
def post_comment(video_id, summary):
    try:
        youtube = get_youtube()
        res = youtube.commentThreads().insert(part="snippet", body={
            "snippet": {
                "videoId": video_id,
                "topLevelComment": {"snippet": {"textOriginal": summary}}
            }
        }).execute()
        conn.execute("INSERT INTO processed VALUES (?, ?)", (video_id, datetime.now().isoformat()))
        conn.commit()
        return f"https://youtube.com/watch?v={video_id}&lc={res['id']}"
    except Exception as e:
        print(f"Post failed: {e}")
        return None

# === Search New Videos ===
def search_new_videos():
    youtube = get_youtube()
    query = KEYWORDS.replace(',', ' OR ')
    published_after = (datetime.utcnow() - timedelta(hours=1)).isoformat("T") + "Z"
    
    request = youtube.search().list(
        part="snippet",
        q=query,
        type="video",
        order="date",
        publishedAfter=published_after,
        maxResults=10
    )
    response = request.execute()
    
    new_videos = []
    for item in response.get('items', []):
        vid = item['id']['videoId']
        title = item['snippet']['title']
        if not conn.execute("SELECT 1 FROM processed WHERE video_id=?", (vid,)).fetchone():
            new_videos.append((vid, title))
    return new_videos

# === Main Automation Loop ===
def run_bot():
    while True:
        print(f"[{datetime.now()}] Scanning for new videos...")
        videos = search_new_videos()
        for vid, title in videos:
            print(f"Processing: {vid} - {title}")
            transcript = get_transcript(vid)
            if transcript:
                summary = generate_summary(transcript, title, vid)
                if summary:
                    link = post_comment(vid, summary)
                    if link:
                        print(f"Posted: {link}")
                    else:
                        print("Post failed")
                else:
                    print("Summary failed")
            else:
                print("No transcript")
            time.sleep(30)  # Avoid rate limits
        time.sleep(CHECK_INTERVAL)

# === Web Dashboard API (for Base44) ===
@app.route('/status')
def status():
    count = conn.execute("SELECT COUNT(*) FROM processed").fetchone()[0]
    return jsonify({"processed": count, "running": True})

@app.route('/history')
def history():
    rows = conn.execute("SELECT video_id, posted_at FROM processed ORDER BY posted_at DESC LIMIT 50").fetchall()
    return jsonify([{"video_id": r[0], "posted_at": r[1]} for r in rows])

# === Start Bot in Background ===
if __name__ == '__main__':
    threading.Thread(target=run_bot, daemon=True).start()
    app.run(host='0.0.0.0', port=8080)